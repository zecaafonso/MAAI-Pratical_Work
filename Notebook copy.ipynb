{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba100bb9",
   "metadata": {},
   "source": [
    "Com base nos dados demográficos, hábitos de estudo e estilo de vida, podemos prever se um estudante apresenta risco de depressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, roc_auc_score, confusion_matrix,classification_report, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09391a78",
   "metadata": {},
   "source": [
    "## - Ler Dataset e imformaçoes basicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Carregar dados\n",
    "df=pd.read_csv(\"student_depression_dataset.csv\")\n",
    "\n",
    "# Informações gerais do dataset\n",
    "print(\"DATASET ORGINAL\")\n",
    "print(f\"Dimensoes: {df.shape}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "# Primeiras linhas do dataset\n",
    "print(f\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "display(df.head())    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728fa7d",
   "metadata": {},
   "source": [
    "## Exploraçao inicial do Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features disponiveis no dataset\n",
    "features =['id', 'Gender', 'Age', 'City', 'Profession', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "            'Job Satisfaction', 'Sleep Duration', 'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?', 'Work/Study Hours',\n",
    "              'Financial Stress', 'Family History of Mental Illness', 'Depression']\n",
    "print(f\"features disponiveis:{features}\")\n",
    "\n",
    "#Tipos de dados\n",
    "print(\"\\nTipos de dados:\")\n",
    "tipos_dados = pd.DataFrame({\n",
    "    'Coluna': df.columns,\n",
    "    'Tipo': df.dtypes.values,\n",
    "    'Valores Únicos': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "display(tipos_dados)   \n",
    "print(df.describe())\n",
    "\n",
    "#valores nulos e duplicados\n",
    "print(f\"Total Valores nulos: {df.isnull().sum().sum()}\")\n",
    "print(f\"Valores nulos:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nLinhas duplicadas: {df.duplicated().sum()}\")\n",
    "print(f\"Total de linhas no dataset: {df.shape[0]}\") \n",
    "  \n",
    "  \n",
    "corr_cols = ['Age','Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "            'Job Satisfaction','Work/Study Hours', 'Depression']\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, cbar_kws={'label': 'Correlação'})\n",
    "plt.title('Matriz de Correlação (Variáveis Numéricas)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1bce0",
   "metadata": {},
   "source": [
    "## Clean_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df.copy()\n",
    "print(f\"Features atuais: {list(df_copy.columns)}\")\n",
    "print(f\"Valores nulos: {df_copy.isnull().sum().sum()}\")\n",
    "print(f\"Linhas duplicadas: {df_copy.duplicated().sum()}\")\n",
    "print(f\"Total de linhas no dataset: {df.shape[0]}\") \n",
    "\n",
    "#features numericas\n",
    "numericas =df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nfeatures numericas:{numericas}\")\n",
    "df_copy[numericas] = df_copy[numericas].fillna(df_copy[numericas].median())\n",
    "print(f\"valores nulos preenchidos com mediana\")\n",
    "#features categoricas\n",
    "categoricas=df_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nfeatures categoricas:{categoricas}\")\n",
    "df_copy[categoricas] = df_copy[categoricas].fillna(df_copy[categoricas].mode().iloc[0])\n",
    "print(f\"valores nulos preenchidos com moda\")\n",
    "\n",
    "# verificar nulos apos novas features\n",
    "print(f\"Total de valores nulos depois da limpeza: {df_copy.isnull().sum().sum()}\")\n",
    "\n",
    "# Remover colunas redundantes/desnecessárias\n",
    "cols_to_drop = ['id',#nao vai ser necessario para a previsao \n",
    "                'City',# para ser menos limitante mais generalizado \n",
    "                'Profession',# para ser menos limitante mais generalizado \n",
    "                'Degree',# para ser menos limitante mais generalizado \n",
    "                'Work Pressure',\n",
    "                'Job Satisfaction'\n",
    "                ]\n",
    "df_copy = df_copy.drop(columns=[c for c in cols_to_drop if c in df_copy.columns])\n",
    "print(f\"\\nColunas removidas: {cols_to_drop}\")\n",
    "print(f\"Features finais: {list(df_copy.columns)}\")\n",
    "\n",
    "\n",
    "print(f\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "display(df_copy.head())   \n",
    "print(f\"\\nDataset após pré-processamento: {df_copy.shape}\")\n",
    "print(f\"Colunas finais ({len(df_copy.columns)}):\")\n",
    "for i, col in enumerate(df_copy.columns, 1):\n",
    "    if col =='Depression':\n",
    "     print(f\"{i}. {col}(target)\")\n",
    "    else:\n",
    "       print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269bd82",
   "metadata": {},
   "source": [
    "## ANÁLISE DA VARIÁVEL TARGET 'Depression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores únicos\n",
    "print(f\"Valores únicos em 'Depression': {df_copy['Depression'].unique()}\")\n",
    "print(f\"Tipo de dados: {df_copy['Depression'].dtype}\")\n",
    "\n",
    "# Distribuição\n",
    "depression_dist = df_copy['Depression'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nDistribuição de 'Depression':\")\n",
    "print(depression_dist)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(data=df_copy, x='Depression')\n",
    "plt.title('Distribuição da Depressão (Target)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Depressão (0=Não, 1=Sim)')\n",
    "plt.ylabel('Número de Estudantes')\n",
    "\n",
    "# Adicionar porcentagens\n",
    "total = len(df_copy)\n",
    "for p in ax.patches:\n",
    "    percentage = f'{100 * p.get_height()/total:.1f}%'\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y_height = p.get_height()\n",
    "    ax.annotate(percentage, (x, y_height + total*0.01), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ee7f9",
   "metadata": {},
   "source": [
    "## Preparaçao de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Identificar categóricas\n",
    "categorical_features = df_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nVariáveis Categóricas ({len(categorical_features)}):\")\n",
    "print(f\"  {categorical_features}\")\n",
    "print(f\"\\nVariáveis Numéricas ({len(numerical_features)}):\")\n",
    "print(f\"  {numerical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dee41e",
   "metadata": {},
   "source": [
    "## Encodign de features categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar cópia para não afetar original\n",
    "df_encoded = df_copy.copy()\n",
    "\n",
    "#VARIÁVEIS BINÁRIAS - LabelEncoder\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"VARIÁVEIS BINÁRIAS\")\n",
    "print(\"=\"*40)\n",
    "binary_cols = ['Gender','Family History of Mental Illness','Have you ever had suicidal thoughts ?']\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        encoded_col = f\"{col}_encoded\"\n",
    "        df_encoded[encoded_col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "       \n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"   Original: {df_encoded[col].unique()}\")\n",
    "        print(f\"   Encoded:  {df_encoded[encoded_col].unique()}\")\n",
    "\n",
    "#VARIÁVEIS ORDINAIS -Mapeamento manual\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"VARIÁVEIS ORDINAIS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "#Sleep Duration\n",
    "if 'Sleep Duration' in df_encoded.columns:\n",
    "    print(f\"\\nSleep Duration - Ordem lógica:\")\n",
    "    # Primeiro: limpar as aspas extras\n",
    "    df_encoded['Sleep Duration'] = df_encoded['Sleep Duration'].str.replace(\"'\", \"\")\n",
    "    \n",
    "    # Mapeamento(ordem crescente de horas)\n",
    "    sleep_mapping = {\n",
    "        'Less than 5 hours': 1,    # Muito pouco\n",
    "        '5-6 hours': 2,            # Pouco\n",
    "        '7-8 hours': 3,            # Normal/Recomendado\n",
    "        'More than 8 hours': 4,    # Muito\n",
    "        'Others': 2.5              # Intermediário (como pode ser mais ou menos)\n",
    "    }\n",
    "    \n",
    "    df_encoded['Sleep Duration_encoded'] = df_encoded['Sleep Duration'].map(sleep_mapping)\n",
    "    print(f\"   Mapeamento aplicado: {sleep_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Sleep Duration_encoded'].unique())}\")\n",
    "\n",
    "# Dietary Habits\n",
    "if 'Dietary Habits' in df_encoded.columns:\n",
    "    print(f\"\\nDietary Habits - Ordem de saúde:\")\n",
    "    \n",
    "    dietary_mapping = {\n",
    "        'Unhealthy': 1,     # Menos saudável\n",
    "        'Others': 2,        # Neutro/Desconhecido\n",
    "        'Moderate': 3,      # Moderado\n",
    "        'Healthy': 4        # Mais saudável\n",
    "    }\n",
    "    \n",
    "    df_encoded['Dietary Habits_encoded'] = df_encoded['Dietary Habits'].map(dietary_mapping) \n",
    "    print(f\"   Mapeamento aplicado: {dietary_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Dietary Habits_encoded'].unique())}\")\n",
    "\n",
    "#Financial Stress\n",
    "if 'Financial Stress' in df_encoded.columns:\n",
    "    print(f\"\\nFinancial Stress - Escala 1-5:\")\n",
    "    \n",
    "    # Converter para string para tratamento uniforme\n",
    "    df_encoded['Financial Stress'] = df_encoded['Financial Stress'].astype(str)\n",
    "    \n",
    "    financial_mapping = {\n",
    "        '1.0': 1, '1': 1,   # Baixo stress\n",
    "        '2.0': 2, '2': 2,\n",
    "        '3.0': 3, '3': 3,   # Moderado\n",
    "        '4.0': 4, '4': 4,\n",
    "        '5.0': 5, '5': 5,   # Alto stress\n",
    "        '?': 3,   # Tratar como moderado\n",
    "    }\n",
    "    \n",
    "    df_encoded['Financial Stress_encoded'] = df_encoded['Financial Stress'].map(financial_mapping)\n",
    "    print(f\"   Mapeamento aplicado: {financial_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Financial Stress_encoded'].unique())}\")\n",
    "\n",
    "\n",
    "#REMOVER COLUNAS ORIGINAIS CATEGÓRICAS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIMPEZA E ORGANIZAÇÃO FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Listar todas as colunas codificadas criadas\n",
    "encoded_columns = [col for col in df_encoded.columns if '_encoded' in col or '_freq' in col or '_target' in col]\n",
    "print(f\"\\nColunas codificadas criadas ({len(encoded_columns)}):\")\n",
    "for col in encoded_columns:\n",
    "    print(f\"   • {col}\")\n",
    "\n",
    "#remover colunas originais categóricas\n",
    "cols_to_drop = [col for col in categorical_features if col in df_encoded.columns]\n",
    "df_encoded = df_encoded.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\nColunas categóricas originais removidas: {cols_to_drop}\")\n",
    "\n",
    "# Verificar resultado final\n",
    "print(f\"\\nDataset após encoding:\")\n",
    "print(f\"Shape: {df_encoded.shape}\")\n",
    "print(f\"Colunas: {list(df_encoded.columns)}\")\n",
    "print(f\"Tipos de dados:\")\n",
    "print(df_encoded.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb299147",
   "metadata": {},
   "source": [
    "## Divisao de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover coluna target das features\n",
    "X = df_encoded.drop('Depression', axis=1)\n",
    "#variável target\n",
    "y = df_encoded['Depression'].copy()\n",
    "\n",
    "print(f\"Shape final:\")\n",
    "print(f\"  X (features): {X.shape}\")\n",
    "print(f\"  y (target): {y.shape}\")\n",
    "\n",
    "# Verificar tipos de dados em X\n",
    "print(f\"\\nTipos de dados em X:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f40d5",
   "metadata": {},
   "source": [
    "## Treinar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c4ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir mantendo proporção das classes (stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\" Divisão estratificada:\")\n",
    "print(f\"Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X):.1%})\")\n",
    "print(f\"Teste:  {X_test.shape[0]} amostras ({X_test.shape[0]/len(X):.1%})\")\n",
    "\n",
    "print(f\"\\n Distribuição no Treino:\")\n",
    "train_dist = y_train.value_counts(normalize=True) * 100\n",
    "print(f\"Classe 0: {train_dist[0]:.1f}%\")\n",
    "print(f\"Classe 1: {train_dist[1]:.1f}%\")\n",
    "\n",
    "print(f\"\\nDistribuição no Teste:\")\n",
    "test_dist = y_test.value_counts(normalize=True) * 100\n",
    "print(f\"Classe 0: {test_dist[0]:.1f}%\")\n",
    "print(f\"Classe 1: {test_dist[1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5682a5",
   "metadata": {},
   "source": [
    "## - NORMALIZAÇÃO DAS FEATURES NUMÉRICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a459bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NORMALIZAÇÃO DAS FEATURES\")\n",
    "print(\"=\"*60)\n",
    "# Identificar colunas numéricas\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar apenas nas colunas numéricas\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(f\"{len(num_cols)} features numéricas normalizadas:\")\n",
    "for col in num_cols:\n",
    "  print(f\"{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "# Dicionário para armazenar resultados\n",
    "results = {}\n",
    "\n",
    "# Lista de modelos para testar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"\\nTreinando e avaliando modelos...\")\n",
    "\n",
    "# Testar cada modelo\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Treinar modelo\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Fazer previsões\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calcular probabilidades (se disponível)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        else:\n",
    "            auc = 0.5  # Valor neutro se não tiver predict_proba\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Tempo de execução\n",
    "        exec_time = time.time() - start_time\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        results[model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc,\n",
    "            'Time (s)': exec_time\n",
    "        }\n",
    "        \n",
    "        print(f\" Treinado em {exec_time:.2f}s\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro: {str(e)[:50]}...\")\n",
    "        results[model_name] = {\n",
    "            'Accuracy': 0,\n",
    "            'Precision': 0,\n",
    "            'Recall': 0,\n",
    "            'F1-Score': 0,\n",
    "            'AUC-ROC': 0,\n",
    "            'Time (s)': 0\n",
    "        }\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Ordenar por F1-Score (melhor métrica geral)\n",
    "results_df_sorted = results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS DA COMPARACAO DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOrdenado por F1-Score (melhor para dados desbalanceados):\")\n",
    "print(results_df_sorted[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'Time (s)']].round(4))\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Gráfico 1: Comparação de Accuracy\n",
    "axes[0, 0].barh(results_df_sorted.index, results_df_sorted['Accuracy'])\n",
    "axes[0, 0].set_xlabel('Accuracy')\n",
    "axes[0, 0].set_title('Comparação de Accuracy entre Modelos')\n",
    "axes[0, 0].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 2: Comparação de F1-Score\n",
    "axes[0, 1].barh(results_df_sorted.index, results_df_sorted['F1-Score'])\n",
    "axes[0, 1].set_xlabel('F1-Score')\n",
    "axes[0, 1].set_title('Comparação de F1-Score entre Modelos')\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 3: Comparação de AUC-ROC\n",
    "axes[1, 0].barh(results_df_sorted.index, results_df_sorted['AUC-ROC'])\n",
    "axes[1, 0].set_xlabel('AUC-ROC')\n",
    "axes[1, 0].set_title('Comparação de AUC-ROC entre Modelos')\n",
    "axes[1, 0].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 4: Tempo de execução\n",
    "axes[1, 1].barh(results_df_sorted.index, results_df_sorted['Time (s)'])\n",
    "axes[1, 1].set_xlabel('Tempo (segundos)')\n",
    "axes[1, 1].set_title('Tempo de Treinamento por Modelo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Análise dos melhores modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALISE DOS MELHORES MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top 3 modelos por F1-Score\n",
    "top_3 = results_df_sorted.head(3)\n",
    "print(f\"\\n TOP 3 MODELOS (por F1-Score):\")\n",
    "for i, (model_name, metrics) in enumerate(top_3.iterrows(), 1):\n",
    "    print(f\"\\n{i}. {model_name}:\")\n",
    "    print(f\"- F1-Score: {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"- Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"- Recall:   {metrics['Recall']:.4f}\")\n",
    "    print(f\"- AUC-ROC:  {metrics['AUC-ROC']:.4f}\")\n",
    "    print(f\"- Tempo:    {metrics['Time (s)']:.2f}s\")\n",
    "\n",
    "# Escolher o melhor modelo\n",
    "melhor_modelo_nome = results_df_sorted.index[0]\n",
    "melhor_modelo = models[melhor_modelo_nome]\n",
    "\n",
    "print(f\"\\n MELHOR MODELO SELECIONADO: {melhor_modelo_nome}\")\n",
    "print(f\"- F1-Score: {results_df_sorted.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"- Motivo: Balance entre precision e recall\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f677a",
   "metadata": {},
   "source": [
    "## RAMDOM FOREST\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e372ccc",
   "metadata": {},
   "source": [
    "## - Porque usar Ramdom Forest?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc181c",
   "metadata": {},
   "source": [
    "Após testar 6 algoritmos diferentes (Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, K-Neighbors, Naive Bayes), o Gradient Boosting apresentou o melhor F1-Score (0.8715), seguido pelo Random Forest (0.8638) e Naive Bayes (0.8625). O Random Forest obteve um F1-Score de 0.8638, ocupando a 2ª posição.\n",
    "\n",
    "A escolha do Random Forest justifica-se pelos seguintes fatores:\n",
    "\n",
    "- Diferença mínima de performance: O Random Forest apresenta apenas 0.9% a menos de recall que o Gradient Boosting (87.8% vs 88.7%), uma diferença insignificante para aplicação prática.\n",
    "\n",
    "- Superioridade em interpretabilidade: O Random Forest fornece feature importance nativa, permitindo identificar os fatores mais relevantes para depressão estudantil.\n",
    "\n",
    "- Eficiência computacional: O Random Forest é 4x mais rápido (0.31s vs 1.25s), importante para sistemas de triagem em tempo real.\n",
    "\n",
    "- Robustez: Menos sensível a overfitting e mais estável com dados incompletos, comum em questionários de saúde mental.\n",
    "\n",
    "- Aplicabilidade: Mais fácil de implementar em ambiente de produção e explicar para profissionais de saúde não-técnicos.\n",
    "\n",
    "Portanto, optou-se pelo Random Forest, que oferece o melhor equilíbrio entre performance preditiva, interpretabilidade dos resultados e eficiência computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98d2f2",
   "metadata": {},
   "source": [
    "## - Treinar modelo de Ramdom Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598b462",
   "metadata": {},
   "source": [
    "Para maximizar a performance do modelo Random Forest, realizou-se uma otimização de hiperparâmetros utilizando GridSearchCV com validação cruzada.  Este método testa exaustivamente todas as combinações pré-definidas de hiperparâmetros, utilizando validação cruzada de 3 folds para avaliar cada configuração.\n",
    "\n",
    "Hiperparâmetros otimizados:\n",
    "\n",
    "- n_estimators: Número de árvores na floresta \n",
    "\n",
    "- max_depth: Profundidade máxima das árvores\n",
    "\n",
    "- min_samples_split: Número mínimo de amostras para dividir um nó\n",
    "\n",
    "- min_samples_leaf: Número mínimo de amostras em uma folha\n",
    "\n",
    "- max_features: Número de features consideradas para melhor split\n",
    "\n",
    "- bootstrap: Amostragem com reposição\n",
    "\n",
    "A métrica de avaliação foi o F1-Score, selecionada por sua adequação a problemas com classes desbalanceadas. O Grid Search identificou a combinação ótima de hiperparâmetros que maximiza a capacidade preditiva do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0037538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros para RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],           # Número de árvores\n",
    "    'max_depth': [5, 10, 15, None],          # Profundidade máxima\n",
    "    'min_samples_split': [2, 5, 10],         # Mínimo amostras para dividir\n",
    "    'min_samples_leaf': [1, 2, 4],           # Mínimo amostras nas folhas\n",
    "    'max_features': ['sqrt', 'log2'],        # Número de features para split\n",
    "    'bootstrap': [True, False]               # Amostragem com reposição\n",
    "}\n",
    "# GridSearchCV\n",
    "print(\"\\nExecutando GridSearchCV...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    scoring='f1',            # Otimizar F1-Score (melhor para desbalanceado)\n",
    "    n_jobs=-1,               # Usar todos os cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nMelhores hiperparametros encontrados:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"Melhor F1-Score na validacao: {grid_search.best_score_:.4f}\")\n",
    "# Usar o melhor modelo\n",
    "rf_model = grid_search.best_estimator_\n",
    "print(f\"\\nModelo otimizado treinado com {rf_model.n_estimators} arvores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5728",
   "metadata": {},
   "source": [
    "## - Avaliaçao do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AVALIAÇÃO DO MODELO\")\n",
    "print(\"=\"*60)\n",
    "# Previsões\n",
    "y_train_pred = rf_model.predict(X_train_scaled)\n",
    "y_train_proba = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "y_test_pred = rf_model.predict(X_test_scaled)\n",
    "y_test_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"PERFORMANCE NO TREINO:\")\n",
    "print(f\"  Acurácia:  {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"   Precisão:  {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  AUC-ROC:   {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "\n",
    "print(\"\\nPERFORMANCE NO TESTE:\")\n",
    "print(f\"  Acurácia:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Precisão:  {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  AUC-ROC:   {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "\n",
    "#Visualização dos resultados\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZAÇÃO DOS RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Sem Depressão', 'Com Depressão'],\n",
    "            yticklabels=['Sem Depressão', 'Com Depressão'])\n",
    "plt.title('Matriz de Confusão - Random Forest', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.xlabel('Previsto', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMatriz de Confusão:\")\n",
    "print(f\"  Verdadeiros Negativos (VN): {cm[0, 0]} - Previu não depressão e era não depressão\")\n",
    "print(f\"  Falsos Positivos (FP):     {cm[0, 1]} - Previu depressão mas era não depressão\")\n",
    "print(f\"  Falsos Negativos (FN):     {cm[1, 0]} - Previu não depressão mas era depressão\")\n",
    "print(f\"  Verdadeiros Positivos (VP): {cm[1, 1]} - Previu depressão e era depressão\")\n",
    "\n",
    "#Relatório de Classificação\n",
    "print(\"\\nRELATÓRIO DE CLASSIFICAÇÃO DETALHADO:\")\n",
    "print(classification_report(y_test, y_test_pred,\n",
    "                           target_names=['Sem Depressão', 'Com Depressão']))\n",
    "\n",
    "#Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label=f'Random Forest (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleatório')\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='darkorange')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "plt.title('Curva ROC - Random Forest para Depressão Estudantil', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('curva_roc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b176902",
   "metadata": {},
   "source": [
    "## ANÁLISE DAS VARIÁVEIS MAIS IMPORTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANÁLISE DAS VARIÁVEIS MAIS IMPORTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Obter importâncias\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Variável': X.columns,\n",
    "    'Importância': rf_model.feature_importances_\n",
    "}).sort_values('Importância', ascending=False)\n",
    "\n",
    "# Visualizar top 15\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_features = feature_importance.head(15)\n",
    "bars = plt.barh(range(len(top_features)), top_features['Importância'])\n",
    "plt.yticks(range(len(top_features)), top_features['Variável'])\n",
    "plt.xlabel('Importância', fontsize=12)\n",
    "plt.title('Top Variáveis para Previsão de Depressão', fontsize=16, fontweight='bold')\n",
    "plt.gca().invert_yaxis()  # Maior importância no topo\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, (bar, importance) in enumerate(zip(bars, top_features['Importância'])):\n",
    "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,\n",
    "             f'{importance:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('importancia_variaveis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74178a",
   "metadata": {},
   "source": [
    "## Resumo do modelo criado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO FINAL E CONCLUSÕES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular métricas finais\n",
    "acuracia = accuracy_score(y_test, y_test_pred)\n",
    "precisao = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\"\"\n",
    " RESULTADO DO MODELO DE PREVISÃO DE DEPRESSÃO\n",
    "\n",
    " DADOS UTILIZADOS:\n",
    "   - Total de estudantes: {df.shape[0]}\n",
    "   - Com depressão: {sum(y == 1)} ({sum(y == 1)/len(y):.1%})\n",
    "   - Sem depressão: {sum(y == 0)} ({sum(y == 0)/len(y):.1%})\n",
    "   - Variáveis preditoras: {X.shape[1]}\n",
    "\n",
    " MODELO RANDOM FOREST:\n",
    "   - Número de árvores: {rf_model.n_estimators}\n",
    "   - Variáveis por split: {rf_model.max_features}\n",
    "   - Balanceamento: {'Sim' if rf_model.class_weight else 'Não'}\n",
    "\n",
    " DESEMPENHO NO TESTE:\n",
    "   - Acurácia:  {acuracia:.2%}\n",
    "   - Precisão:  {precisao:.2%} (dos previstos como depressão, quantos realmente têm)\n",
    "   - Recall:    {recall:.2%} (dos que têm depressão, quantos foram identificados)\n",
    "   - F1-Score:  {f1:.2%} (média harmônica entre precisão e recall)\n",
    "   - AUC-ROC:   {auc_score:.2%} (capacidade de discriminar entre classes)\n",
    "\n",
    " FATORES MAIS IMPORTANTES:\n",
    "   1. {feature_importance.iloc[0]['Variável']} ({feature_importance.iloc[0]['Importância']:.3%})\n",
    "   2. {feature_importance.iloc[1]['Variável']} ({feature_importance.iloc[1]['Importância']:.3%})\n",
    "   3. {feature_importance.iloc[2]['Variável']} ({feature_importance.iloc[2]['Importância']:.3%})\n",
    "\n",
    " IMPLICAÇÕES PRÁTICAS:\n",
    "   - O modelo pode identificar {recall:.1%} dos estudantes com depressão\n",
    "   - {precisao:.1%} das previsões positivas são corretas\n",
    "   - Focando nos fatores mais importantes, podemos criar programas preventivos\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb62c8f",
   "metadata": {},
   "source": [
    "## Previsao \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76acfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Faz a previsao com os dados fornecidos\n",
    "def fazer_previsao(dados_aluno):\n",
    "\n",
    "    # Garantir que temos todas as colunas necessarias\n",
    "    colunas_necessarias = X.columns.tolist()\n",
    "    \n",
    "    # Criar DataFrame com os dados\n",
    "    dados_df = pd.DataFrame([dados_aluno])\n",
    "    \n",
    "    # Adicionar colunas faltantes (se houver)\n",
    "    for col in colunas_necessarias:\n",
    "        if col not in dados_df.columns:\n",
    "            print(f\"Aviso: Coluna '{col}' nao fornecida. Usando valor medio.\")\n",
    "            if col in X.columns:\n",
    "                dados_df[col] = X[col].mean()\n",
    "    \n",
    "    # Reordenar colunas\n",
    "    dados_df = dados_df[colunas_necessarias]\n",
    "    \n",
    "    # Normalizar dados\n",
    "    dados_normalizados = dados_df.copy()\n",
    "    dados_normalizados[num_cols] = scaler.transform(dados_df[num_cols])\n",
    "    \n",
    "    # Fazer previsao\n",
    "    probabilidade = rf_model.predict_proba(dados_normalizados)[0][1]\n",
    "    predicao = rf_model.predict(dados_normalizados)[0]\n",
    "    \n",
    "    return predicao, probabilidade\n",
    "\n",
    "## Funcao para prever depressao \n",
    "def prever_depressao_aluno(dados_aluno_dict):\n",
    "    # Verificar se temos todas as colunas necessarias\n",
    "    colunas_obrigatorias = [\n",
    "        'Age', 'Gender_encoded', 'CGPA', 'Academic Pressure',\n",
    "        'Study Satisfaction', 'Work/Study Hours', 'Sleep Duration_encoded',\n",
    "        'Dietary Habits_encoded', 'Have you ever had suicidal thoughts ?_encoded',\n",
    "        'Financial Stress_encoded', 'Family History of Mental Illness_encoded'\n",
    "    ]\n",
    "    \n",
    "    # Verificar colunas faltantes\n",
    "    faltantes = [col for col in colunas_obrigatorias if col not in dados_aluno_dict]\n",
    "    if faltantes:\n",
    "        print(f\"Aviso: Colunas faltantes: {faltantes}\")\n",
    "        print(\"   Usando valores medios para colunas faltantes...\")\n",
    "        \n",
    "        # Adicionar valores medios para colunas faltantes\n",
    "        for col in faltantes:\n",
    "            if col in X.columns:\n",
    "                dados_aluno_dict[col] = X[col].mean()\n",
    "            else:\n",
    "                # Valor padrao baseado no tipo de variavel\n",
    "                if 'encoded' in col:\n",
    "                    dados_aluno_dict[col] = 0\n",
    "                elif 'Pressure' in col or 'Satisfaction' in col:\n",
    "                    dados_aluno_dict[col] = 5.0\n",
    "                else:\n",
    "                    dados_aluno_dict[col] = 0\n",
    "    \n",
    "    # Fazer previsao\n",
    "    predicao, probabilidade = fazer_previsao(dados_aluno_dict)\n",
    "    \n",
    "    # Criar resultado estruturado\n",
    "    resultado = {\n",
    "        'tem_depressao': bool(predicao),\n",
    "        'probabilidade_depressao': float(probabilidade),\n",
    "        'probabilidade_percentual': float(probabilidade * 100),\n",
    "        'risco': 'ALTO' if predicao == 1 else 'BAIXO',\n",
    "        'recomendacao': 'Avaliacao psicologica recomendada' if predicao == 1 else 'Manter acompanhamento',\n",
    "        'dados_analisados': len(dados_aluno_dict)\n",
    "    }\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "## Sistema interativo para prever depressao\n",
    "def sistema_previsao():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SISTEMA DE PREVISAO DE DEPRESSAO ESTUDANTIL\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nForneca os dados do aluno abaixo:\\n\")\n",
    "    \n",
    "    dados_aluno = {}\n",
    "    \n",
    "    # Dados que precisam ser fornecidos\n",
    "    dados_aluno['Age'] = float(input(\"Idade do aluno (ex: 21.0): \"))\n",
    "    dados_aluno['Gender_encoded'] = int(input(\"Genero (0=Feminino, 1=Masculino): \"))\n",
    "    dados_aluno['CGPA'] = float(input(\"Nota media CGPA (0-10, ex: 7.5): \"))\n",
    "    dados_aluno['Academic Pressure'] = float(input(\"Pressao Academica (1-10): \"))\n",
    "    dados_aluno['Study Satisfaction'] = float(input(\"Satisfacao com Estudos (1-10): \"))\n",
    "    dados_aluno['Work/Study Hours'] = float(input(\"Horas de estudo/trabalho por dia (ex: 8.0): \"))\n",
    "    \n",
    "    print(\"\\nQualidade do Sono (1-4):\")\n",
    "    print(\"1 = Menos de 5 horas\")\n",
    "    print(\"2 = 5-6 horas\")\n",
    "    print(\"3 = 7-8 horas\")\n",
    "    print(\"4 = Mais de 8 horas\")\n",
    "    dados_aluno['Sleep Duration_encoded'] = int(input(\"Escolha (1-4): \"))\n",
    "    \n",
    "    print(\"\\nHabitos Alimentares (1-4):\")\n",
    "    print(\"1 = Nao saudavel\")\n",
    "    print(\"2 = Outros\")\n",
    "    print(\"3 = Moderado\")\n",
    "    print(\"4 = Saudavel\")\n",
    "    dados_aluno['Dietary Habits_encoded'] = int(input(\"Escolha (1-4): \"))\n",
    "    \n",
    "    dados_aluno['Have you ever had suicidal thoughts ?_encoded'] = int(input(\"Pensamentos suicidas? (0=Nao, 1=Sim): \"))\n",
    "    dados_aluno['Financial Stress_encoded'] = float(input(\"Estresse Financeiro (1-5): \"))\n",
    "    dados_aluno['Family History of Mental Illness_encoded'] = int(input(\"Historico familiar doenca mental? (0=Nao, 1=Sim): \"))\n",
    "    \n",
    "    # Fazer previsao\n",
    "    resultado = prever_depressao_aluno(dados_aluno)\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESULTADO DA PREVISAO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nPrevisao: {'COM DEPRESSAO' if resultado['tem_depressao'] else 'SEM DEPRESSAO'}\")\n",
    "    print(f\"Probabilidade: {resultado['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Nivel de Risco: {resultado['risco']}\")\n",
    "\n",
    "    return resultado\n",
    "\n",
    "## Exemplos de uso do sistema\n",
    "def exemplos():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXEMPLOS DE USO DO SISTEMA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Exemplo 1: Aluno com alto risco\n",
    "    print(\"\\nEXEMPLO 1: Aluno com multiplos fatores de risco\")\n",
    "    exemplo_alto_risco = {\n",
    "        'Age': 20.0,\n",
    "        'Gender_encoded': 1,\n",
    "        'CGPA': 6.2,\n",
    "        'Academic Pressure': 9.0,\n",
    "        'Study Satisfaction': 3.0,\n",
    "        'Work/Study Hours': 10.0,\n",
    "        'Sleep Duration_encoded': 1,\n",
    "        'Dietary Habits_encoded': 1,\n",
    "        'Have you ever had suicidal thoughts ?_encoded': 1,\n",
    "        'Financial Stress_encoded': 4.0,\n",
    "        'Family History of Mental Illness_encoded': 1\n",
    "    }\n",
    "    \n",
    "    resultado1 = prever_depressao_aluno(exemplo_alto_risco)\n",
    "    print(f\"\\nResultado: {'DEPRESSAO' if resultado1['tem_depressao'] else 'Sem depressao'}\")\n",
    "    print(f\"Probabilidade: {resultado1['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Risco: {resultado1['risco']}\")\n",
    "    \n",
    "    # Exemplo 2: Aluno com baixo risco\n",
    "    print(\"\\nEXEMPLO 2: Aluno com baixo risco\")\n",
    "    exemplo_baixo_risco = {\n",
    "        'Age': 22.0,\n",
    "        'Gender_encoded': 0,\n",
    "        'CGPA': 8.5,\n",
    "        'Academic Pressure': 4.0,\n",
    "        'Study Satisfaction': 8.0,\n",
    "        'Work/Study Hours': 6.0,\n",
    "        'Sleep Duration_encoded': 3,\n",
    "        'Dietary Habits_encoded': 4,\n",
    "        'Have you ever had suicidal thoughts ?_encoded': 0,\n",
    "        'Financial Stress_encoded': 2.0,\n",
    "        'Family History of Mental Illness_encoded': 0\n",
    "    }\n",
    "    \n",
    "    resultado2 = prever_depressao_aluno(exemplo_baixo_risco)\n",
    "    print(f\"\\nResultado: {'DEPRESSAO' if resultado2['tem_depressao'] else 'Sem depressao'}\")\n",
    "    print(f\"Probabilidade: {resultado2['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Risco: {resultado2['risco']}\")\n",
    "\n",
    "## Menu principal interativo\n",
    "def menu_principal():\n",
    "  \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SISTEMA DE PREVISAO DE DEPRESSAO ESTUDANTIL\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nEscolha uma opcao:\")\n",
    "        print(\"\\n1. Fazer previsao para um aluno\")\n",
    "        print(\"2. Ver exemplos de uso\")\n",
    "        print(\"3. Sair\")\n",
    "        \n",
    "        opcao = input(\"\\nOpcao: \")\n",
    "        \n",
    "        if opcao == \"1\":\n",
    "            sistema_previsao()\n",
    "            \n",
    "            # Perguntar se quer fazer outra previsao\n",
    "            continuar = input(\"\\nDeseja fazer outra previsao? (s/n): \")\n",
    "            if continuar.lower() != 's':\n",
    "                break\n",
    "        \n",
    "        elif opcao == \"2\":\n",
    "            exemplos()\n",
    "            input(\"\\nPressione Enter para continuar...\")\n",
    "        \n",
    "        elif opcao == \"3\":\n",
    "            print(\"\\nObrigado por usar o sistema!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"Opcao invalida. Tente novamente.\")\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Iniciar menu\n",
    "menu_principal()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
