{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ba9bcc",
   "metadata": {},
   "source": [
    "# MAAI-Pratical_Work- Sistema de Previsão de Depressão Estudantil\n",
    "## Feito por : Jose Afonso Pereira Monteiro Nº : 21083\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ae9e8",
   "metadata": {},
   "source": [
    "## Business Goals\n",
    "\n",
    "### Objetivos principais\n",
    "Desenvolver um sistema para prever se um aluno estaria em risco de depressao com base nos dados demograficos,habitos de estudo e estilo de vida para responder as seguintes questões:\n",
    "  - podemos prever se um estudante está em risco de depressão?\n",
    "  - Quais fatores acadêmicos, psicológicos e de estilo de vida melhor prevem o risco de depressão em estudantes universitários?\n",
    "\n",
    "O objetivo geral deste estudo é desenvolver e implementar um sistema completo de previsão de depressão estudantil. Os objetivos específicos incluem:\n",
    "1) Realizar análise exploratória abrangente das características dos estudantes\n",
    "2) Identificar parâmetros otimos para modelagem preditiva\n",
    "3) Analisar a relação entre fatores de risco e probabilidade de depressão\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057cffd",
   "metadata": {},
   "source": [
    "## Importaçao de bibliotecas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d8ae1",
   "metadata": {},
   "source": [
    "- importamos todas as bibliotecas necessárias para a análise de dados, visualização, pré-processamento e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, roc_auc_score, confusion_matrix,classification_report, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09391a78",
   "metadata": {},
   "source": [
    "## Carregamento e Exploração Inicial do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56840fa3",
   "metadata": {},
   "source": [
    "\n",
    "- Carregamos o dataset e realizamos uma exploração inicial para entender sua estrutura, dimensões e conteúdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Carregar dados\n",
    "df=pd.read_csv(\"student_depression_dataset.csv\")\n",
    "\n",
    "# Informações gerais do dataset\n",
    "print(\"DATASET ORGINAL\")\n",
    "print(f\"Dimensoes: {df.shape}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "# Primeiras linhas do dataset\n",
    "print(f\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "display(df.head())    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728fa7d",
   "metadata": {},
   "source": [
    "## Exploração Detalhada do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6289374",
   "metadata": {},
   "source": [
    "- Aqui realizamos uma análise mais detalhada dos tipos de dados, valores únicos, estatísticas descritivas, valores nulos e duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features disponiveis no dataset\n",
    "features =['id', 'Gender', 'Age', 'City', 'Profession', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "            'Job Satisfaction', 'Sleep Duration', 'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?', 'Work/Study Hours',\n",
    "              'Financial Stress', 'Family History of Mental Illness', 'Depression']\n",
    "print(f\"features disponiveis:{features}\")\n",
    "\n",
    "#Tipos de dados\n",
    "print(\"\\nTipos de dados:\")\n",
    "tipos_dados = pd.DataFrame({\n",
    "    'Coluna': df.columns,\n",
    "    'Tipo': df.dtypes.values,\n",
    "    'Valores Únicos': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "display(tipos_dados)   \n",
    "print(df.describe())\n",
    "\n",
    "#valores nulos e duplicados\n",
    "print(f\"Total Valores nulos: {df.isnull().sum().sum()}\")\n",
    "print(f\"Valores nulos:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nLinhas duplicadas: {df.duplicated().sum()}\")\n",
    "print(f\"Total de linhas no dataset: {df.shape[0]}\") \n",
    "  \n",
    "  \n",
    "corr_cols = ['Age','Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "            'Job Satisfaction','Work/Study Hours', 'Depression']\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, cbar_kws={'label': 'Correlação'})\n",
    "plt.title('Matriz de Correlação (Variáveis Numéricas)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1bce0",
   "metadata": {},
   "source": [
    "## Limpeza e Pré-processamento de Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1806151",
   "metadata": {},
   "source": [
    "- Nesta seção, realizamos a limpeza dos dados, tratando valores nulos, removendo colunas irrelevantes e preparando o dataset para modelagem.\n",
    "\n",
    "As Colunas removidas foram selecionadas pelo os seguintes motivos:\n",
    "- limitavam muito a seleçao do utilizador como o 'City','Profession'\n",
    "- irrelevantes como por exemplo o 'id'\n",
    "- porque ao verificar a importancia de cada variavel apos o treinamento do modelo,a importancia ser zero ou muito baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy=df.copy()\n",
    "\n",
    "print(f\"Features atuais: {list(df_copy.columns)}\")\n",
    "print(f\"Valores nulos: {df_copy.isnull().sum().sum()}\")\n",
    "print(f\"Linhas duplicadas: {df_copy.duplicated().sum()}\")\n",
    "print(f\"Total de linhas no dataset: {df.shape[0]}\") \n",
    "\n",
    "#features numericas\n",
    "numericas =df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nfeatures numericas:{numericas}\")\n",
    "#valores nulos preenchidos com mediana\n",
    "df_copy[numericas] = df_copy[numericas].fillna(df_copy[numericas].median())\n",
    "print(f\"valores nulos preenchidos com mediana\")\n",
    "\n",
    "#features categoricas\n",
    "categoricas=df_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nfeatures categoricas:{categoricas}\")\n",
    "#valores nulos preenchidos com moda\n",
    "df_copy[categoricas] = df_copy[categoricas].fillna(df_copy[categoricas].mode().iloc[0])\n",
    "print(f\"valores nulos preenchidos com moda\")\n",
    "\n",
    "# verificar nulos apos limpeza\n",
    "print(f\"Total de valores nulos depois da limpeza: {df_copy.isnull().sum().sum()}\")\n",
    "\n",
    "# Remover colunas redundantes/desnecessárias\n",
    "cols_to_drop = ['id',#nao vai ser necessario para a previsao \n",
    "                'City',# para ser menos limitante mais generalizado \n",
    "                'Profession',# para ser menos limitante mais generalizado \n",
    "                'Degree',# importancia muito baixa\n",
    "                'Work Pressure',# importancia muito baixa\n",
    "                'Job Satisfaction'# importancia muito baixa\n",
    "                ]\n",
    "df_copy = df_copy.drop(columns=[c for c in cols_to_drop if c in df_copy.columns])\n",
    "print(f\"\\nColunas removidas: {cols_to_drop}\")\n",
    "print(f\"Features finais: {list(df_copy.columns)}\")\n",
    "\n",
    "# Exibir as primeiras linhas do dataset após o pré-processamento\n",
    "print(f\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "display(df_copy.head())  \n",
    "\n",
    "#Features finais e dimensoes\n",
    "print(f\"\\nDataset após pré-processamento: {df_copy.shape}\")\n",
    "print(f\"Colunas finais ({len(df_copy.columns)}):\")\n",
    "for i, col in enumerate(df_copy.columns, 1):\n",
    "    if col =='Depression':\n",
    "     print(f\"{i}. {col}(target)\")\n",
    "    else:\n",
    "       print(f\"{i}. {col}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269bd82",
   "metadata": {},
   "source": [
    "##  Análise da Variável Target 'Depression'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d03cfd",
   "metadata": {},
   "source": [
    "Esta seção analisa a distribuição da variável alvo (Depression), que é o que queremos prever. É crucial entender o balanceamento das classes antes de treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores únicos\n",
    "print(f\"Valores únicos em 'Depression': {df_copy['Depression'].unique()}\")\n",
    "print(f\"Tipo de dados: {df_copy['Depression'].dtype}\")\n",
    "\n",
    "# Distribuição\n",
    "depression_dist = df_copy['Depression'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nDistribuição de 'Depression':\")\n",
    "print(depression_dist)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(data=df_copy, x='Depression')\n",
    "plt.title('Distribuição da Depressão (Target)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Depressão (0=Não, 1=Sim)')\n",
    "plt.ylabel('Número de Estudantes')\n",
    "\n",
    "# Adicionar percentagens\n",
    "total = len(df_copy)\n",
    "for p in ax.patches:\n",
    "    percentage = f'{100 * p.get_height()/total:.1f}%'\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y_height = p.get_height()\n",
    "    ax.annotate(percentage, (x, y_height + total*0.01), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ee7f9",
   "metadata": {},
   "source": [
    "## Preparação de Dados para Codificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fd0bf",
   "metadata": {},
   "source": [
    "Esta seção identifica e separa as variáveis categóricas e numéricas do dataset após o pré-processamento. Esta separação é crucial porque:\n",
    "1. Variáveis categóricas precisam ser convertidas para formato numérico (através de Label Encoding ou One-Hot Encoding)\n",
    "2. Variáveis numéricas podem precisar de normalização ou padronização\n",
    "3. Diferentes tipos de variáveis requerem diferentes tratamentos antes da modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Identificar categóricas\n",
    "categorical_features = df_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nVariáveis Categóricas ({len(categorical_features)}):\")\n",
    "print(f\"  {categorical_features}\")\n",
    "print(f\"\\nVariáveis Numéricas ({len(numerical_features)}):\")\n",
    "print(f\"  {numerical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dee41e",
   "metadata": {},
   "source": [
    "## Encoding de Features Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd86b4",
   "metadata": {},
   "source": [
    "Esta seção converte todas as variáveis categóricas em formato numérico através de diferentes técnicas de encoding. O encoding é necessário porque a maioria dos algoritmos de machine learning só trabalha com dados numéricos. Aqui utilizamos duas abordagens diferentes baseadas no tipo de variável:\n",
    "\n",
    "1. **Label Encoding para variáveis binárias**: Variáveis com apenas duas categorias\n",
    "2. **Mapeamento manual para variáveis ordinais**: Variáveis com ordem natural entre as categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar cópia para não afetar original\n",
    "df_encoded = df_copy.copy()\n",
    "\n",
    "#VARIÁVEIS BINÁRIAS - LabelEncoder\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"VARIÁVEIS BINÁRIAS\")\n",
    "print(\"=\"*40)\n",
    "binary_cols = ['Gender','Family History of Mental Illness','Have you ever had suicidal thoughts ?']\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        encoded_col = f\"{col}_encoded\"\n",
    "        df_encoded[encoded_col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "       \n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"   Original: {df_encoded[col].unique()}\")\n",
    "        print(f\"   Encoded:  {df_encoded[encoded_col].unique()}\")\n",
    "\n",
    "#VARIÁVEIS ORDINAIS -Mapeamento manual\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"VARIÁVEIS ORDINAIS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "#Sleep Duration\n",
    "if 'Sleep Duration' in df_encoded.columns:\n",
    "    print(f\"\\nSleep Duration - Ordem lógica:\")\n",
    "    # Primeiro: limpar as aspas extras\n",
    "    df_encoded['Sleep Duration'] = df_encoded['Sleep Duration'].str.replace(\"'\", \"\")\n",
    "    \n",
    "    # Mapeamento(ordem crescente de horas)\n",
    "    sleep_mapping = {\n",
    "        'Less than 5 hours': 1,    # Muito pouco\n",
    "        '5-6 hours': 2,            # Pouco\n",
    "        '7-8 hours': 3,            # Normal/Recomendado\n",
    "        'More than 8 hours': 4,    # Muito\n",
    "        'Others': 2.5              # Intermediário (como pode ser mais ou menos)\n",
    "    }\n",
    "    \n",
    "    df_encoded['Sleep Duration_encoded'] = df_encoded['Sleep Duration'].map(sleep_mapping)\n",
    "    print(f\"   Mapeamento aplicado: {sleep_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Sleep Duration_encoded'].unique())}\")\n",
    "\n",
    "# Dietary Habits\n",
    "if 'Dietary Habits' in df_encoded.columns:\n",
    "    print(f\"\\nDietary Habits - Ordem de saúde:\")\n",
    "    \n",
    "    dietary_mapping = {\n",
    "        'Unhealthy': 1,     # Menos saudável\n",
    "        'Others': 2,        # Neutro/Desconhecido\n",
    "        'Moderate': 3,      # Moderado\n",
    "        'Healthy': 4        # Mais saudável\n",
    "    }\n",
    "    \n",
    "    df_encoded['Dietary Habits_encoded'] = df_encoded['Dietary Habits'].map(dietary_mapping) \n",
    "    print(f\"   Mapeamento aplicado: {dietary_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Dietary Habits_encoded'].unique())}\")\n",
    "\n",
    "#Financial Stress\n",
    "if 'Financial Stress' in df_encoded.columns:\n",
    "    print(f\"\\nFinancial Stress - Escala 1-5:\")\n",
    "    \n",
    "    # Converter para string para tratamento uniforme\n",
    "    df_encoded['Financial Stress'] = df_encoded['Financial Stress'].astype(str)\n",
    "    \n",
    "    financial_mapping = {\n",
    "        '1.0': 1, '1': 1,   # Baixo stress\n",
    "        '2.0': 2, '2': 2,\n",
    "        '3.0': 3, '3': 3,   # Moderado\n",
    "        '4.0': 4, '4': 4,\n",
    "        '5.0': 5, '5': 5,   # Alto stress\n",
    "        '?': 3,   # Tratar como moderado\n",
    "    }\n",
    "    \n",
    "    df_encoded['Financial Stress_encoded'] = df_encoded['Financial Stress'].map(financial_mapping)\n",
    "    print(f\"   Mapeamento aplicado: {financial_mapping}\")\n",
    "    print(f\"   Valores únicos após: {sorted(df_encoded['Financial Stress_encoded'].unique())}\")\n",
    "\n",
    "\n",
    "#REMOVER COLUNAS ORIGINAIS CATEGÓRICAS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIMPEZA E ORGANIZAÇÃO FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Listar todas as colunas codificadas criadas\n",
    "encoded_columns = [col for col in df_encoded.columns if '_encoded' in col or '_freq' in col or '_target' in col]\n",
    "print(f\"\\nColunas codificadas criadas ({len(encoded_columns)}):\")\n",
    "for col in encoded_columns:\n",
    "    print(f\"-{col}\")\n",
    "\n",
    "#remover colunas originais categóricas\n",
    "cols_to_drop = [col for col in categorical_features if col in df_encoded.columns]\n",
    "df_encoded = df_encoded.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\nColunas categóricas originais removidas: {cols_to_drop}\")\n",
    "\n",
    "# Verificar resultado final\n",
    "print(f\"\\nDataset após encoding:\")\n",
    "print(f\"Shape: {df_encoded.shape}\")\n",
    "print(f\"Colunas: {list(df_encoded.columns)}\")\n",
    "print(f\"Tipos de dados:\")\n",
    "print(df_encoded.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb299147",
   "metadata": {},
   "source": [
    "## Separação de Features e Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea466e",
   "metadata": {},
   "source": [
    "Nesta etapa, separamos o dataset em duas partes:\n",
    "1. **X (Features)**: Todas as variáveis preditoras que serão usadas para fazer as previsões\n",
    "2. **y (Target)**: A variável que queremos prever (Depression - 0 ou 1)\n",
    "\n",
    "Esta separação é necessária porque os algoritmos de machine learning aprendem a relação entre X e y, e depois usam essa relação para fazer previsões em novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover coluna target das features\n",
    "X = df_encoded.drop('Depression', axis=1)\n",
    "#variável target\n",
    "y = df_encoded['Depression'].copy()\n",
    "\n",
    "print(f\"Shape final:\")\n",
    "print(f\"  X (features): {X.shape}\")\n",
    "print(f\"  y (target): {y.shape}\")\n",
    "\n",
    "# Verificar tipos de dados em X\n",
    "print(f\"\\nTipos de dados em X:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f40d5",
   "metadata": {},
   "source": [
    "## Divisão dos Dados em Conjuntos de Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ff537",
   "metadata": {},
   "source": [
    "\n",
    "Nesta etapa, dividimos o dataset em dois subconjuntos:\n",
    "- **Conjunto de Treino (80%)**: Usado para treinar o modelo\n",
    "- **Conjunto de Teste (20%)**: Usado para avaliar o modelo em dados não vistos\n",
    "\n",
    " O parâmetro **stratify=y** garante que a proporção das classes seja mantida em ambos os conjuntos,garantindo que tenham a mesma proporção de classes deprimidas/não deprimidas.\n",
    "\n",
    " O parâmetro **Random State = 42** garante reprodutibilidade, sempre obterá a mesma divisão.\n",
    " \n",
    " A **Proporção 80/20** e suficiente para o modelo aprender padrões complexos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c4ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir mantendo proporção das classes (stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, # Features\n",
    "    y, # Target\n",
    "    test_size=0.2,#20% para teste|80% para treino \n",
    "    random_state=42,#para reprodutibilidade \n",
    "    stratify=y#manter proporção das classes\n",
    ")\n",
    "\n",
    "print(f\" Divisão estratificada:\")\n",
    "print(f\"Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X):.1%})\")\n",
    "print(f\"Teste:  {X_test.shape[0]} amostras ({X_test.shape[0]/len(X):.1%})\")\n",
    "\n",
    "print(f\"\\n Distribuição no Treino:\")\n",
    "train_dist = y_train.value_counts(normalize=True) * 100\n",
    "print(f\"Classe 0: {train_dist[0]:.1f}%\")\n",
    "print(f\"Classe 1: {train_dist[1]:.1f}%\")\n",
    "\n",
    "print(f\"\\nDistribuição no Teste:\")\n",
    "test_dist = y_test.value_counts(normalize=True) * 100\n",
    "print(f\"Classe 0: {test_dist[0]:.1f}%\")\n",
    "print(f\"Classe 1: {test_dist[1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5682a5",
   "metadata": {},
   "source": [
    "## Normalização das Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec0411",
   "metadata": {},
   "source": [
    "Nesta etapa, aplicamos a normalização (StandardScaler) às features numéricas para garantir que todas tenham a mesma escala.O \n",
    "\n",
    "**StandardScaler** transforma os dados para ter média 0 e desvio padrão 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8559aad",
   "metadata": {},
   "source": [
    "## -Por que usar StandardScaler?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefc941",
   "metadata": {},
   "source": [
    "\n",
    "   - **Robusto a outliers**: Menos sensível que MinMaxScaler\n",
    "   - **Preserva distribuição**: Mantém a forma da distribuição original\n",
    "   - **Interpretabilidade**: Valores em unidades de desvio padrão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a459bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NORMALIZAÇÃO DAS FEATURES\")\n",
    "print(\"=\"*60)\n",
    "# Identificar colunas numéricas\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar apenas nas colunas numéricas\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Aplicar normalização\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(f\"{len(num_cols)} features numéricas normalizadas:\")\n",
    "for col in num_cols:\n",
    "  print(f\"{col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58df16",
   "metadata": {},
   "source": [
    "## Comparação de Múltiplos Modelos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda008d",
   "metadata": {},
   "source": [
    "Nesta seção, implementamos uma comparação sistemática de 6 diferentes algoritmos de machine learning para identificar qual tem o melhor desempenho na previsão de risco de depressão. Esta abordagem é essencial porque:\n",
    "\n",
    "1. **Diferentes algoritmos têm diferentes pontos fortes**: Alguns são melhores com dados lineares, outros com não-lineares\n",
    "2. **Evita viés de algoritmo único**: Não assumimos que um algoritmo específico é o melhor\n",
    "3. **Identificação do algoritmo mais adequado**: Baseado nas características específicas do nosso dataset\n",
    "\n",
    "### Algoritmos Comparados:\n",
    "\n",
    "| Algoritmo | Pontos Fortes | Pontos Fracos | Melhor para |\n",
    "|-----------|--------------|---------------|-------------|\n",
    "| **Logistic Regression** | Interpretável, rápido, bom baseline | Linear apenas | Relações lineares |\n",
    "| **Decision Tree** | Interpretável, não precisa normalização | Overfitting fácil | Datasets pequenos |\n",
    "| **Random Forest** | Reduz overfitting, robusto | Menos interpretável | Classificação geral |\n",
    "| **Gradient Boosting** | Alta performance, combina árvores | Lento, overfitting se mal ajustado | Competições Kaggle |\n",
    "| **XGBoost** | Otimizado, rápido, boa performance | Hiperparâmetros complexos | Performance extrema |\n",
    "| **Naive Bayes** | Muito rápido, bom com features independentes | Suposição ingênua (independência) | Texto, datasets grandes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "# Dicionário para armazenar resultados\n",
    "results = {}\n",
    "\n",
    "# Lista de modelos para testar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"\\nTreinando e avaliando modelos...\")\n",
    "\n",
    "# Testar cada modelo\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Treinar modelo\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Fazer previsões\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calcular probabilidades (se disponível)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        else:\n",
    "            auc = 0.5  # Valor neutro se não tiver predict_proba\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Tempo de execução\n",
    "        exec_time = time.time() - start_time\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        results[model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'AUC-ROC': auc,\n",
    "            'Time (s)': exec_time\n",
    "        }\n",
    "        \n",
    "        print(f\" Treinado em {exec_time:.2f}s\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro: {str(e)[:50]}...\")\n",
    "        results[model_name] = {\n",
    "            'Accuracy': 0,\n",
    "            'Precision': 0,\n",
    "            'Recall': 0,\n",
    "            'F1-Score': 0,\n",
    "            'AUC-ROC': 0,\n",
    "            'Time (s)': 0\n",
    "        }\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Ordenar por F1-Score (melhor métrica geral)\n",
    "results_df_sorted = results_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS DA COMPARACAO DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOrdenado por F1-Score (melhor para dados desbalanceados):\")\n",
    "print(results_df_sorted[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'Time (s)']].round(4))\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Gráfico 1: Comparação de Accuracy\n",
    "axes[0, 0].barh(results_df_sorted.index, results_df_sorted['Accuracy'])\n",
    "axes[0, 0].set_xlabel('Accuracy')\n",
    "axes[0, 0].set_title('Comparação de Accuracy entre Modelos')\n",
    "axes[0, 0].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 2: Comparação de F1-Score\n",
    "axes[0, 1].barh(results_df_sorted.index, results_df_sorted['F1-Score'])\n",
    "axes[0, 1].set_xlabel('F1-Score')\n",
    "axes[0, 1].set_title('Comparação de F1-Score entre Modelos')\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 3: Comparação de AUC-ROC\n",
    "axes[1, 0].barh(results_df_sorted.index, results_df_sorted['AUC-ROC'])\n",
    "axes[1, 0].set_xlabel('AUC-ROC')\n",
    "axes[1, 0].set_title('Comparação de AUC-ROC entre Modelos')\n",
    "axes[1, 0].set_xlim([0, 1])\n",
    "\n",
    "# Gráfico 4: Tempo de execução\n",
    "axes[1, 1].barh(results_df_sorted.index, results_df_sorted['Time (s)'])\n",
    "axes[1, 1].set_xlabel('Tempo (segundos)')\n",
    "axes[1, 1].set_title('Tempo de Treinamento por Modelo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Análise dos melhores modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALISE DOS MELHORES MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top 3 modelos por F1-Score\n",
    "top_3 = results_df_sorted.head(3)\n",
    "print(f\"\\n TOP 3 MODELOS (por F1-Score):\")\n",
    "for i, (model_name, metrics) in enumerate(top_3.iterrows(), 1):\n",
    "    print(f\"\\n{i}. {model_name}:\")\n",
    "    print(f\"- F1-Score: {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"- Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"- Recall:   {metrics['Recall']:.4f}\")\n",
    "    print(f\"- AUC-ROC:  {metrics['AUC-ROC']:.4f}\")\n",
    "    print(f\"- Tempo:    {metrics['Time (s)']:.2f}s\")\n",
    "\n",
    "# Escolher o melhor modelo\n",
    "melhor_modelo_nome = results_df_sorted.index[0]\n",
    "melhor_modelo = models[melhor_modelo_nome]\n",
    "\n",
    "print(f\"\\n MELHOR MODELO SELECIONADO: {melhor_modelo_nome}\")\n",
    "print(f\"- F1-Score: {results_df_sorted.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"- Motivo: Balance entre precision e recall\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f677a",
   "metadata": {},
   "source": [
    "## RAMDOM FOREST\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e372ccc",
   "metadata": {},
   "source": [
    "## - Porque usar Ramdom Forest?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc181c",
   "metadata": {},
   "source": [
    "Após testar 6 algoritmos diferentes (Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, K-Neighbors, Naive Bayes), o Gradient Boosting apresentou o melhor F1-Score (0.8715), seguido pelo Random Forest (0.8638) e Naive Bayes (0.8625). O Random Forest obteve um F1-Score de 0.8638, ocupando a 2ª posição.\n",
    "\n",
    "A escolha do Random Forest justifica-se pelos seguintes fatores:\n",
    "\n",
    "- Diferença mínima de performance: O Random Forest apresenta apenas 0.9% a menos de recall que o Gradient Boosting (87.8% vs 88.7%), uma diferença insignificante para aplicação prática.\n",
    "\n",
    "- Superioridade em interpretabilidade: O Random Forest fornece feature importance nativa, permitindo identificar os fatores mais relevantes para depressão estudantil.\n",
    "\n",
    "- Eficiência computacional: O Random Forest é mais rápido (0.31s vs 1.25s), importante para sistemas de triagem em tempo real.\n",
    "\n",
    "- Robustez: Menos sensível a overfitting e mais estável com dados incompletos, comum em questionários de saúde mental.\n",
    "\n",
    "- Aplicabilidade: Mais fácil de implementar em ambiente de produção e explicar para profissionais de saúde não-técnicos.\n",
    "\n",
    "Portanto, optou-se pelo Random Forest, que oferece o melhor equilíbrio entre performance preditiva, interpretabilidade dos resultados e eficiência computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98d2f2",
   "metadata": {},
   "source": [
    "## - Treinar modelo de Ramdom Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598b462",
   "metadata": {},
   "source": [
    "Para maximizar a performance do modelo Random Forest, realizou-se uma otimização de hiperparâmetros utilizando RandomizedSearchCV com validação cruzada.\n",
    "\n",
    "Hiperparâmetros otimizados:\n",
    "\n",
    "- n_estimators: Número de árvores na floresta \n",
    "\n",
    "- max_depth: Profundidade máxima das árvores\n",
    "\n",
    "- min_samples_split: Número mínimo de amostras para dividir um nó\n",
    "\n",
    "- min_samples_leaf: Número mínimo de amostras em uma folha\n",
    "\n",
    "- max_features: Número de features consideradas para melhor split\n",
    "\n",
    "- bootstrap: Amostragem com reposição\n",
    "\n",
    "A métrica de avaliação foi o F1-Score, selecionada por sua adequação a problemas com classes desbalanceadas. A otimização testou 15 combinações aleatórias de hiperparâmetros, identificando a configuração ótima que maximiza a capacidade preditiva do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e27a0",
   "metadata": {},
   "source": [
    "### Por que RandomizedSearchCV em vez de GridSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c6ebc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Método | Vantagens | Desvantagens | Melhor para |\n",
    "|--------|-----------|--------------|-------------|\n",
    "| **RandomizedSearchCV** | Mais rápido, boa cobertura, menos computacional | Pode não encontrar ótimo absoluto | Espaços grandes de parâmetros |\n",
    "| **GridSearchCV** | Encontra ótimo exato, exaustivo | Muito lento, explode combinatorialmente | Espaços pequenos de parâmetros |\n",
    "\n",
    "**Para nosso caso**: 6 parâmetros × múltiplos valores = grande espaço → RandomizedSearchCV ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0037538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "print(\"Executando otimizacao com RandomizedSearchCV...\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,               # Número de combinações aleatórias\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    scoring='f1',            # Otimizar F1-Score\n",
    "    n_jobs=-1,               # Usar todos os cores\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nMelhores hiperparametros encontrados:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"Melhor F1-Score na validacao: {random_search.best_score_:.4f}\")\n",
    "# Usar o melhor modelo\n",
    "rf_model = random_search.best_estimator_\n",
    "print(f\"\\nModelo otimizado treinado com {rf_model.n_estimators} arvores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5728",
   "metadata": {},
   "source": [
    "## Avaliaçao do Modelo Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce91d8b",
   "metadata": {},
   "source": [
    "Nesta seção, realizamos uma avaliação detalhada do modelo Random Forest, analisando seu desempenho tanto no conjunto de treino quanto no conjunto de teste. Esta avaliação é crucial para:\n",
    "\n",
    "1. **Identificar overfitting/underfitting**: Comparando performance treino vs teste\n",
    "2. **Compreender erros do modelo**: Através da matriz de confusão\n",
    "3. **Avaliar capacidade discriminativa**: Usando curva ROC\n",
    "\n",
    "### Métricas Avaliadas:\n",
    "\n",
    "| Métrica | Fórmula | Interpretação no Contexto |\n",
    "|---------|---------|---------------------------|\n",
    "| **Acurácia** | (TP+TN)/(TP+TN+FP+FN) | Porcentagem total de acertos |\n",
    "| **Precisão** | TP/(TP+FP) | Dos previstos como deprimidos, quantos realmente estão? |\n",
    "| **Recall** | TP/(TP+FN) | Dos realmente deprimidos, quantos identificamos? |\n",
    "| **F1-Score** | 2×(P×R)/(P+R) | Balance entre precisão e recall |\n",
    "| **AUC-ROC** | Área sob curva ROC | Capacidade discriminativa geral |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AVALIAÇÃO DO MODELO\")\n",
    "print(\"=\"*60)\n",
    "# Previsões\n",
    "y_train_pred = rf_model.predict(X_train_scaled)\n",
    "y_train_proba = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "y_test_pred = rf_model.predict(X_test_scaled)\n",
    "y_test_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"PERFORMANCE NO TREINO:\")\n",
    "print(f\"  Acurácia:  {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"   Precisão:  {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  AUC-ROC:   {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "\n",
    "print(\"\\nPERFORMANCE NO TESTE:\")\n",
    "print(f\"  Acurácia:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Precisão:  {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  AUC-ROC:   {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "\n",
    "#Visualização dos resultados\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZAÇÃO DOS RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "#Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Sem Depressão', 'Com Depressão'],\n",
    "            yticklabels=['Sem Depressão', 'Com Depressão'])\n",
    "plt.title('Matriz de Confusão - Random Forest', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.xlabel('Previsto', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMatriz de Confusão:\")\n",
    "print(f\"  Verdadeiros Negativos (VN): {cm[0, 0]} - Previu não depressão e era não depressão\")\n",
    "print(f\"  Falsos Positivos (FP):     {cm[0, 1]} - Previu depressão mas era não depressão\")\n",
    "print(f\"  Falsos Negativos (FN):     {cm[1, 0]} - Previu não depressão mas era depressão\")\n",
    "print(f\"  Verdadeiros Positivos (VP): {cm[1, 1]} - Previu depressão e era depressão\")\n",
    "\n",
    "#Relatório de Classificação\n",
    "print(\"\\nRELATÓRIO DE CLASSIFICAÇÃO DETALHADO:\")\n",
    "print(classification_report(y_test, y_test_pred,\n",
    "                           target_names=['Sem Depressão', 'Com Depressão']))\n",
    "\n",
    "#Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label=f'Random Forest (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleatório')\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='darkorange')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "plt.title('Curva ROC - Random Forest para Depressão Estudantil', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('curva_roc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b176902",
   "metadata": {},
   "source": [
    "## ANÁLISE DAS VARIÁVEIS MAIS IMPORTANTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323957b",
   "metadata": {},
   "source": [
    "Nesta seção, analisamos quais features têm maior influência nas previsões do modelo Random Forest. Esta análise é crucial porque:\n",
    "\n",
    "1. **Interpretabilidade**: Entende quais fatores mais contribuem para o risco de depressão\n",
    "2. **Validação de domínio**: Confirma se variáveis importantes fazem sentido clínico\n",
    "3. **Simplificação de modelo**: Identifica features que podem ser removidas sem perda significativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANÁLISE DAS VARIÁVEIS MAIS IMPORTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Obter importâncias\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Variável': X.columns,\n",
    "    'Importância': rf_model.feature_importances_\n",
    "}).sort_values('Importância', ascending=False)\n",
    "\n",
    "# Visualizar top 15\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_features = feature_importance.head(15)\n",
    "bars = plt.barh(range(len(top_features)), top_features['Importância'])\n",
    "plt.yticks(range(len(top_features)), top_features['Variável'])\n",
    "plt.xlabel('Importância', fontsize=12)\n",
    "plt.title('Top Variáveis para Previsão de Depressão', fontsize=16, fontweight='bold')\n",
    "plt.gca().invert_yaxis()  # Maior importância no topo\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, (bar, importance) in enumerate(zip(bars, top_features['Importância'])):\n",
    "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,\n",
    "             f'{importance:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('importancia_variaveis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74178a",
   "metadata": {},
   "source": [
    "## Resumo do modelo criado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO FINAL E CONCLUSÕES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular métricas finais\n",
    "acuracia = accuracy_score(y_test, y_test_pred)\n",
    "precisao = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\"\"\n",
    " RESULTADO DO MODELO DE PREVISÃO DE DEPRESSÃO\n",
    "\n",
    " DADOS UTILIZADOS:\n",
    "   - Total de estudantes: {df.shape[0]}\n",
    "   - Com depressão: {sum(y == 1)} ({sum(y == 1)/len(y):.1%})\n",
    "   - Sem depressão: {sum(y == 0)} ({sum(y == 0)/len(y):.1%})\n",
    "   - Variáveis preditoras: {X.shape[1]}\n",
    "\n",
    " MODELO RANDOM FOREST:\n",
    "   - Número de árvores: {rf_model.n_estimators}\n",
    "   - Variáveis por split: {rf_model.max_features}\n",
    "   - Balanceamento: {'Sim' if rf_model.class_weight else 'Não'}\n",
    "\n",
    " DESEMPENHO NO TESTE:\n",
    "   - Acurácia:  {acuracia:.2%}\n",
    "   - Precisão:  {precisao:.2%} (dos previstos como depressão, quantos realmente têm)\n",
    "   - Recall:    {recall:.2%} (dos que têm depressão, quantos foram identificados)\n",
    "   - F1-Score:  {f1:.2%} (média harmônica entre precisão e recall)\n",
    "   - AUC-ROC:   {auc_score:.2%} (capacidade de discriminar entre classes)\n",
    "\n",
    " FATORES MAIS IMPORTANTES:\n",
    "   1. {feature_importance.iloc[0]['Variável']} ({feature_importance.iloc[0]['Importância']:.3%})\n",
    "   2. {feature_importance.iloc[1]['Variável']} ({feature_importance.iloc[1]['Importância']:.3%})\n",
    "   3. {feature_importance.iloc[2]['Variável']} ({feature_importance.iloc[2]['Importância']:.3%})\n",
    "\n",
    " IMPLICAÇÕES PRÁTICAS:\n",
    "   - O modelo pode identificar {recall:.1%} dos estudantes com depressão\n",
    "   - {precisao:.1%} das previsões positivas são corretas\n",
    "   - Focando nos fatores mais importantes, podemos criar programas preventivos\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0fec9",
   "metadata": {},
   "source": [
    "## Salvar Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretório para salvar\n",
    "save_dir = \"modelo_salvo\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# SALVAR O MODELO TREINADO\n",
    "model_path = f\"{save_dir}/random_forest_model.pkl\"\n",
    "joblib.dump(rf_model, model_path)\n",
    "print(f\"Modelo salvo: {model_path}\")\n",
    "\n",
    "# SALVAR O SCALER \n",
    "scaler_path = f\"{save_dir}/scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler salvo: {scaler_path}\")\n",
    "\n",
    "# SALVAR AS COLUNAS DO MODELO\n",
    "colunas_modelo = {\n",
    "    'features': X.columns.tolist(),\n",
    "    'target': 'Depression',\n",
    "    'numerical_features': num_cols.tolist(),\n",
    "    'categorical_features_encoded': [col for col in X.columns if '_encoded' in col]\n",
    "}\n",
    "\n",
    "colunas_path = f\"{save_dir}/colunas_modelo.pkl\"\n",
    "joblib.dump(colunas_modelo, colunas_path)\n",
    "print(f\"Colunas do modelo salvas: {colunas_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb62c8f",
   "metadata": {},
   "source": [
    "## Sistema de Previsão Interativo para Depressão Estudantil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a55bc",
   "metadata": {},
   "source": [
    "Nesta seção final, implementamos um sistema completo de previsão que permite usar o modelo treinado para fazer previsões em tempo real. Este sistema transforma nosso modelo de machine learning em uma ferramenta prática e utilizável, com:\n",
    "\n",
    "1. **Interface interativa**: Menu para interação com o usuário\n",
    "2. **Processamento em tempo real**: Previsões instantâneas\n",
    "3. **Tratamento de dados ausentes**: Valores padrão quando informações faltam\n",
    "4. **Interpretação clínica**: Resultados compreensíveis e acionáveis\n",
    "5. **Exemplos demonstrativos**: Casos para validação e compreensão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7764c",
   "metadata": {},
   "source": [
    "ENTRADA DO USUÁRIO -> PRÉ-PROCESSAMENTO -> MODELO -> INTERPRETAÇÃO -> RESULTADO\n",
    "->Dados do aluno Normalização e Random Forest, Risco ,Recomendação\n",
    ",codificação Probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76acfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Faz a previsao com os dados fornecidos\n",
    "def fazer_previsao(dados_aluno):\n",
    "\n",
    "    # Garantir que temos todas as colunas necessarias\n",
    "    colunas_necessarias = X.columns.tolist()\n",
    "    \n",
    "    # Criar DataFrame com os dados\n",
    "    dados_df = pd.DataFrame([dados_aluno])\n",
    "    \n",
    "    # Adicionar colunas faltantes (se houver)\n",
    "    for col in colunas_necessarias:\n",
    "        if col not in dados_df.columns:\n",
    "            print(f\"Aviso: Coluna '{col}' nao fornecida. Usando valor medio.\")\n",
    "            if col in X.columns:\n",
    "                dados_df[col] = X[col].mean()\n",
    "    \n",
    "    # Reordenar colunas\n",
    "    dados_df = dados_df[colunas_necessarias]\n",
    "    \n",
    "    # Normalizar dados\n",
    "    dados_normalizados = dados_df.copy()\n",
    "    dados_normalizados[num_cols] = scaler.transform(dados_df[num_cols])\n",
    "    \n",
    "    # Fazer previsao\n",
    "    probabilidade = rf_model.predict_proba(dados_normalizados)[0][1]\n",
    "    predicao = rf_model.predict(dados_normalizados)[0]\n",
    "    \n",
    "    return predicao, probabilidade\n",
    "\n",
    "## Funcao para prever depressao \n",
    "def prever_depressao_aluno(dados_aluno_dict):\n",
    "    # Verificar se temos todas as colunas necessarias\n",
    "    colunas_obrigatorias = [\n",
    "        'Age', 'Gender_encoded', 'CGPA', 'Academic Pressure',\n",
    "        'Study Satisfaction', 'Work/Study Hours', 'Sleep Duration_encoded',\n",
    "        'Dietary Habits_encoded', 'Have you ever had suicidal thoughts ?_encoded',\n",
    "        'Financial Stress_encoded', 'Family History of Mental Illness_encoded'\n",
    "    ]\n",
    "    \n",
    "    # Verificar colunas faltantes\n",
    "    faltantes = [col for col in colunas_obrigatorias if col not in dados_aluno_dict]\n",
    "    if faltantes:\n",
    "        print(f\"Aviso: Colunas faltantes: {faltantes}\")\n",
    "        print(\"   Usando valores medios para colunas faltantes...\")\n",
    "        \n",
    "        # Adicionar valores medios para colunas faltantes\n",
    "        for col in faltantes:\n",
    "            if col in X.columns:\n",
    "                dados_aluno_dict[col] = X[col].mean()\n",
    "            else:\n",
    "                # Valor padrao baseado no tipo de variavel\n",
    "                if 'encoded' in col:\n",
    "                    dados_aluno_dict[col] = 0\n",
    "                elif 'Pressure' in col or 'Satisfaction' in col:\n",
    "                    dados_aluno_dict[col] = 5.0\n",
    "                else:\n",
    "                    dados_aluno_dict[col] = 0\n",
    "    \n",
    "    # Fazer previsao\n",
    "    predicao, probabilidade = fazer_previsao(dados_aluno_dict)\n",
    "    \n",
    "    # Criar resultado estruturado\n",
    "    resultado = {\n",
    "        'tem_depressao': bool(predicao),\n",
    "        'probabilidade_depressao': float(probabilidade),\n",
    "        'probabilidade_percentual': float(probabilidade * 100),\n",
    "        'risco': 'ALTO' if predicao == 1 else 'BAIXO',\n",
    "        'recomendacao': 'Avaliacao psicologica recomendada' if predicao == 1 else 'Manter acompanhamento',\n",
    "        'dados_analisados': len(dados_aluno_dict)\n",
    "    }\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "## Sistema interativo para prever depressao\n",
    "def sistema_previsao():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SISTEMA DE PREVISAO DE DEPRESSAO ESTUDANTIL\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nForneca os dados do aluno abaixo:\\n\")\n",
    "    \n",
    "    dados_aluno = {}\n",
    "    \n",
    "    # Dados que precisam ser fornecidos\n",
    "    dados_aluno['Age'] = float(input(\"Idade do aluno (ex: 21.0): \"))\n",
    "    dados_aluno['Gender_encoded'] = int(input(\"Genero (0=Feminino, 1=Masculino): \"))\n",
    "    dados_aluno['CGPA'] = float(input(\"Nota media CGPA (0-10, ex: 7.5): \"))\n",
    "    dados_aluno['Academic Pressure'] = float(input(\"Pressao Academica (1-10): \"))\n",
    "    dados_aluno['Study Satisfaction'] = float(input(\"Satisfacao com Estudos (1-10): \"))\n",
    "    dados_aluno['Work/Study Hours'] = float(input(\"Horas de estudo/trabalho por dia (ex: 8.0): \"))\n",
    "    \n",
    "    print(\"\\nQualidade do Sono (1-4):\")\n",
    "    print(\"1 = Menos de 5 horas\")\n",
    "    print(\"2 = 5-6 horas\")\n",
    "    print(\"3 = 7-8 horas\")\n",
    "    print(\"4 = Mais de 8 horas\")\n",
    "    dados_aluno['Sleep Duration_encoded'] = int(input(\"Escolha (1-4): \"))\n",
    "    \n",
    "    print(\"\\nHabitos Alimentares (1-4):\")\n",
    "    print(\"1 = Nao saudavel\")\n",
    "    print(\"2 = Outros\")\n",
    "    print(\"3 = Moderado\")\n",
    "    print(\"4 = Saudavel\")\n",
    "    dados_aluno['Dietary Habits_encoded'] = int(input(\"Escolha (1-4): \"))\n",
    "    \n",
    "    dados_aluno['Have you ever had suicidal thoughts ?_encoded'] = int(input(\"Pensamentos suicidas? (0=Nao, 1=Sim): \"))\n",
    "    dados_aluno['Financial Stress_encoded'] = float(input(\"Estresse Financeiro (1-5): \"))\n",
    "    dados_aluno['Family History of Mental Illness_encoded'] = int(input(\"Historico familiar doenca mental? (0=Nao, 1=Sim): \"))\n",
    "    \n",
    "    # Fazer previsao\n",
    "    resultado = prever_depressao_aluno(dados_aluno)\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESULTADO DA PREVISAO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nPrevisao: {'COM DEPRESSAO' if resultado['tem_depressao'] else 'SEM DEPRESSAO'}\")\n",
    "    print(f\"Probabilidade: {resultado['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Nivel de Risco: {resultado['risco']}\")\n",
    "\n",
    "    return resultado\n",
    "\n",
    "## Exemplos de uso do sistema\n",
    "def exemplos():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXEMPLOS DE USO DO SISTEMA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Exemplo 1: Aluno com alto risco\n",
    "    print(\"\\nEXEMPLO 1: Aluno com multiplos fatores de risco\")\n",
    "    exemplo_alto_risco = {\n",
    "        'Age': 20.0,\n",
    "        'Gender_encoded': 1,\n",
    "        'CGPA': 6.2,\n",
    "        'Academic Pressure': 9.0,\n",
    "        'Study Satisfaction': 3.0,\n",
    "        'Work/Study Hours': 10.0,\n",
    "        'Sleep Duration_encoded': 1,\n",
    "        'Dietary Habits_encoded': 1,\n",
    "        'Have you ever had suicidal thoughts ?_encoded': 1,\n",
    "        'Financial Stress_encoded': 4.0,\n",
    "        'Family History of Mental Illness_encoded': 1\n",
    "    }\n",
    "    \n",
    "    resultado1 = prever_depressao_aluno(exemplo_alto_risco)\n",
    "    print(f\"\\nResultado: {'DEPRESSAO' if resultado1['tem_depressao'] else 'Sem depressao'}\")\n",
    "    print(f\"Probabilidade: {resultado1['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Risco: {resultado1['risco']}\")\n",
    "    \n",
    "    # Exemplo 2: Aluno com baixo risco\n",
    "    print(\"\\nEXEMPLO 2: Aluno com baixo risco\")\n",
    "    exemplo_baixo_risco = {\n",
    "        'Age': 22.0,\n",
    "        'Gender_encoded': 0,\n",
    "        'CGPA': 8.5,\n",
    "        'Academic Pressure': 4.0,\n",
    "        'Study Satisfaction': 8.0,\n",
    "        'Work/Study Hours': 6.0,\n",
    "        'Sleep Duration_encoded': 3,\n",
    "        'Dietary Habits_encoded': 4,\n",
    "        'Have you ever had suicidal thoughts ?_encoded': 0,\n",
    "        'Financial Stress_encoded': 2.0,\n",
    "        'Family History of Mental Illness_encoded': 0\n",
    "    }\n",
    "    \n",
    "    resultado2 = prever_depressao_aluno(exemplo_baixo_risco)\n",
    "    print(f\"\\nResultado: {'DEPRESSAO' if resultado2['tem_depressao'] else 'Sem depressao'}\")\n",
    "    print(f\"Probabilidade: {resultado2['probabilidade_percentual']:.1f}%\")\n",
    "    print(f\"Risco: {resultado2['risco']}\")\n",
    "\n",
    "## Menu principal interativo\n",
    "def menu_principal():\n",
    "  \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SISTEMA DE PREVISAO DE DEPRESSAO ESTUDANTIL\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nEscolha uma opcao:\")\n",
    "        print(\"\\n1. Fazer previsao para um aluno\")\n",
    "        print(\"2. Ver exemplos de uso\")\n",
    "        print(\"3. Sair\")\n",
    "        \n",
    "        opcao = input(\"\\nOpcao: \")\n",
    "        \n",
    "        if opcao == \"1\":\n",
    "            sistema_previsao()\n",
    "            \n",
    "            # Perguntar se quer fazer outra previsao\n",
    "            continuar = input(\"\\nDeseja fazer outra previsao? (s/n): \")\n",
    "            if continuar.lower() != 's':\n",
    "                break\n",
    "        \n",
    "        elif opcao == \"2\":\n",
    "            exemplos()\n",
    "            input(\"\\nPressione Enter para continuar...\")\n",
    "        \n",
    "        elif opcao == \"3\":\n",
    "            print(\"\\nObrigado por usar o sistema!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"Opcao invalida. Tente novamente.\")\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Iniciar menu\n",
    "menu_principal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e399464",
   "metadata": {},
   "source": [
    "## API- servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8104aa",
   "metadata": {},
   "source": [
    "terminal: uvicorn api:app --reload\n",
    "\n",
    "- http://localhost:8000\n",
    "- http://localhost:8000/docs\n",
    "- http://localhost:8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad46f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "app = FastAPI(title=\"Student Depression API\")\n",
    "\n",
    "# Carregar modelo\n",
    "modelo = joblib.load('modelo_salvo/random_forest_model.pkl')\n",
    "scaler = joblib.load('modelo_salvo/scaler.pkl')\n",
    "colunas_info = joblib.load('modelo_salvo/colunas_modelo.pkl')\n",
    "\n",
    "class StudentInput(BaseModel):\n",
    "    Age: float\n",
    "    Gender_encoded: int\n",
    "    CGPA: float\n",
    "    Academic_Pressure: float\n",
    "    Study_Satisfaction: float\n",
    "    Work_Study_Hours: float\n",
    "    Sleep_Duration_encoded: int\n",
    "    Dietary_Habits_encoded: int\n",
    "    Have_you_ever_had_suicidal_thoughts_encoded: int\n",
    "    Financial_Stress_encoded: float\n",
    "    Family_History_of_Mental_Illness_encoded: int\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_depression(student: StudentInput):\n",
    "    try:\n",
    "        # Criar dicionario\n",
    "        dados = {\n",
    "            'Age': student.Age,\n",
    "            'Gender_encoded': student.Gender_encoded,\n",
    "            'CGPA': student.CGPA,\n",
    "            'Academic Pressure': student.Academic_Pressure,\n",
    "            'Study Satisfaction': student.Study_Satisfaction,\n",
    "            'Work/Study Hours': student.Work_Study_Hours,\n",
    "            'Sleep Duration_encoded': student.Sleep_Duration_encoded,\n",
    "            'Dietary Habits_encoded': student.Dietary_Habits_encoded,\n",
    "            'Have you ever had suicidal thoughts ?_encoded': student.Have_you_ever_had_suicidal_thoughts_encoded,\n",
    "            'Financial Stress_encoded': student.Financial_Stress_encoded,\n",
    "            'Family History of Mental Illness_encoded': student.Family_History_of_Mental_Illness_encoded\n",
    "        }\n",
    "        \n",
    "        # Criar DataFrame\n",
    "        df = pd.DataFrame([dados])\n",
    "        \n",
    "        # Adicionar colunas faltantes\n",
    "        for col in colunas_info['features']:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "        \n",
    "        # Ordenar colunas\n",
    "        df = df[colunas_info['features']]\n",
    "        \n",
    "        # Normalizar\n",
    "        df[colunas_info['numerical_features']] = scaler.transform(\n",
    "            df[colunas_info['numerical_features']]\n",
    "        )\n",
    "        \n",
    "        # Prever\n",
    "        probabilidade = modelo.predict_proba(df)[0][1]\n",
    "        predicao = modelo.predict(df)[0]\n",
    "        \n",
    "        return {\n",
    "            \"depressao\": bool(predicao),\n",
    "            \"probabilidade\": float(probabilidade),\n",
    "            \"percentual\": float(probabilidade * 100)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"api\": \"online\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe99f8",
   "metadata": {},
   "source": [
    "APP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451da2b",
   "metadata": {},
   "source": [
    "terminal: streamlit run app.py   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "\n",
    "st.set_page_config(page_title=\"Previsao Depressao Estudantil\")\n",
    "\n",
    "st.title(\"Previsao de Depressao Estudantil\")\n",
    "st.markdown(\"Analise o risco de depressao com base nos dados do estudante\")\n",
    "\n",
    "# Formulario\n",
    "with st.form(\"form_depressao\"):\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        idade = st.number_input(\"Idade\", 17, 30, 21)\n",
    "        genero = st.selectbox(\"Genero\", [\"Feminino (0)\", \"Masculino (1)\"])\n",
    "        cgpa = st.slider(\"CGPA (0-10)\", 0.0, 10.0, 7.5, 0.1)\n",
    "        pressao = st.slider(\"Pressao Academica (1-10)\", 1, 10, 6)\n",
    "        satisfacao = st.slider(\"Satisfacao Estudos (1-10)\", 1, 10, 5)\n",
    "    \n",
    "    with col2:\n",
    "        horas = st.slider(\"Horas Estudo/Dia\", 0, 16, 8)\n",
    "        sono = st.selectbox(\"Sono\", \n",
    "            [\"Menos 5h (1)\", \"5-6h (2)\", \"7-8h (3)\", \"Mais 8h (4)\"])\n",
    "        alimentacao = st.selectbox(\"Alimentacao\",\n",
    "            [\"Nao saudavel (1)\", \"Outros (2)\", \"Moderado (3)\", \"Saudavel (4)\"])\n",
    "        pensamentos = st.selectbox(\"Pensamentos Suicidas\", [\"Nao (0)\", \"Sim (1)\"])\n",
    "        estresse = st.slider(\"Estresse Financeiro (1-5)\", 1, 5, 3)\n",
    "        historico = st.selectbox(\"Historico Familiar\", [\"Nao (0)\", \"Sim (1)\"])\n",
    "    \n",
    "    submit = st.form_submit_button(\"Analisar Risco\")\n",
    "\n",
    "# Processar quando enviar\n",
    "if submit:\n",
    "    # Converter valores\n",
    "    genero_encoded = 0 if \"Feminino\" in genero else 1\n",
    "    sono_encoded = int(sono.split(\"(\")[1].replace(\")\", \"\"))\n",
    "    alimentacao_encoded = int(alimentacao.split(\"(\")[1].replace(\")\", \"\"))\n",
    "    pensamentos_encoded = 0 if \"Nao\" in pensamentos else 1\n",
    "    historico_encoded = 0 if \"Nao\" in historico else 1\n",
    "    \n",
    "    # Preparar dados para API\n",
    "    dados = {\n",
    "        \"Age\": float(idade),\n",
    "        \"Gender_encoded\": genero_encoded,\n",
    "        \"CGPA\": float(cgpa),\n",
    "        \"Academic_Pressure\": float(pressao),\n",
    "        \"Study_Satisfaction\": float(satisfacao),\n",
    "        \"Work_Study_Hours\": float(horas),\n",
    "        \"Sleep_Duration_encoded\": sono_encoded,\n",
    "        \"Dietary_Habits_encoded\": alimentacao_encoded,\n",
    "        \"Have_you_ever_had_suicidal_thoughts_encoded\": pensamentos_encoded,\n",
    "        \"Financial_Stress_encoded\": float(estresse),\n",
    "        \"Family_History_of_Mental_Illness_encoded\": historico_encoded\n",
    "    }\n",
    "    \n",
    "    # Enviar para API\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:8000/predict\", json=dados)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            resultado = response.json()\n",
    "            \n",
    "            # Mostrar resultados\n",
    "            st.markdown(\"---\")\n",
    "            st.header(\"Resultado da Analise\")\n",
    "            \n",
    "            col_res1, col_res2 = st.columns(2)\n",
    "            \n",
    "            with col_res1:\n",
    "                st.metric(\n",
    "                    \"Probabilidade de Depressao\",\n",
    "                    f\"{resultado['percentual']:.1f}%\"\n",
    "                )\n",
    "                \n",
    "                if resultado['depressao']:\n",
    "                    st.error(\"COM DEPRESSAO\")\n",
    "                else:\n",
    "                    st.success(\"SEM DEPRESSAO\")\n",
    "            \n",
    "            with col_res2:\n",
    "                st.metric(\"Nivel de Risco\", resultado['risco'])\n",
    "                st.info(resultado['mensagem'])\n",
    "            \n",
    "            # Explicacao\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(\"Interpretacao:\")\n",
    "            \n",
    "            if resultado['percentual'] < 30:\n",
    "                st.success(\"\"\"\n",
    "                **Baixo Risco:** A probabilidade e baixa. Continue com habitos saudaveis \n",
    "                e mantenha equilibrio entre estudo e vida pessoal.\n",
    "                \"\"\")\n",
    "            elif resultado['percentual'] < 60:\n",
    "                st.warning(\"\"\"\n",
    "                **Risco Moderado:** Atencao necessaria. Considere reduzir estresse, \n",
    "                melhorar qualidade do sono e buscar apoio se necessario.\n",
    "                \"\"\")\n",
    "            else:\n",
    "                st.error(\"\"\"\n",
    "                **Alto Risco:** Recomenda-se avaliacao com profissional de saude mental. \n",
    "                Procure apoio psicologico e converse com alguem de confianca.\n",
    "                \"\"\")\n",
    "        \n",
    "        else:\n",
    "            st.error(f\"Erro na API: {response.status_code}\")\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        st.error(\"\"\"\n",
    "        Nao foi possivel conectar a API.\n",
    "        \n",
    "        Para resolver:\n",
    "        1. Abra um terminal\n",
    "        2. Execute: uvicorn api:app --reload\n",
    "        3. Tente novamente\n",
    "        \"\"\")\n",
    "\n",
    "# Informacoes adicionais\n",
    "with st.expander(\"Sobre o Modelo\"):\n",
    "    st.markdown(\"\"\"\n",
    "    **Modelo Utilizado:** Random Forest Classifier\n",
    "    **Acuracia:** 84.1%\n",
    "    **AUC-ROC:** 91.6%\n",
    "    **F1-Score:** 86.5%\n",
    "    \n",
    "    **Fatores Analisados:**\n",
    "    - Dados demograficos (idade, genero)\n",
    "    - Desempenho academico (CGPA, pressao, satisfacao)\n",
    "    - Habitos de vida (sono, alimentacao, horas estudo)\n",
    "    - Fatores psicologicos (pensamentos suicidas, estresse)\n",
    "    - Historico familiar\n",
    "    \n",
    "    **Aviso:** Esta e uma ferramenta de triagem, nao substitui avaliacao profissional.\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
